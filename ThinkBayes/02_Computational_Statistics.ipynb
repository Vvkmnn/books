{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Statistics\n",
    "\n",
    "## Distributions\n",
    "\n",
    "In statistics a <span>**distribution**</span> is a set of values and\n",
    "their corresponding probabilities.\n",
    "\n",
    "For example, if you roll a six-sided die, the set of possible values is\n",
    "the numbers 1 to 6, and the probability associated with each value is\n",
    "1/6.\n",
    "\n",
    "As another example, you might be interested in how many times each word\n",
    "appears in common English usage. You could build a distribution that\n",
    "includes each word and how many times it appears.\n",
    "\n",
    "To represent a distribution in Python, you could use a dictionary that\n",
    "maps from each value to its probability. I have written a class called\n",
    "<span>Pmf</span> that uses a Python dictionary in exactly that way, and\n",
    "provides a number of useful methods. I called the class Pmf in reference\n",
    "to a <span>**probability mass function**</span>, which is a way to\n",
    "represent a distribution mathematically.\n",
    "\n",
    "<span>Pmf</span> is defined in a Python module I wrote to accompany this\n",
    "book, <span>thinkbayes.py</span>. You can download it from\n",
    "<http://thinkbayes.com/thinkbayes.py>. For more information see\n",
    "Section [download].\n",
    "\n",
    "To use <span>Pmf</span> you can import it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './code')\n",
    "# Go into the subdirectory \n",
    "\n",
    "from thinkbayes import Pmf\n",
    "# Grab the thinkbayes script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code builds a Pmf to represent the distribution of\n",
    "outcomes for a six-sided die:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Pmf in module thinkbayes:\n",
      "\n",
      "class Pmf(_DictWrapper)\n",
      " |  Represents a probability mass function.\n",
      " |  \n",
      " |  Values can be any hashable type; probabilities are floating-point.\n",
      " |  Pmfs are not necessarily normalized.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Pmf\n",
      " |      _DictWrapper\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  AddConstant(self, other)\n",
      " |      Computes the Pmf of the sum a constant and  values from self.\n",
      " |      \n",
      " |      other: a number\n",
      " |      \n",
      " |      returns: new Pmf\n",
      " |  \n",
      " |  AddPmf(self, other)\n",
      " |      Computes the Pmf of the sum of values drawn from self and other.\n",
      " |      \n",
      " |      other: another Pmf\n",
      " |      \n",
      " |      returns: new Pmf\n",
      " |  \n",
      " |  CredibleInterval(self, percentage=90)\n",
      " |      Computes the central credible interval.\n",
      " |      \n",
      " |      If percentage=90, computes the 90% CI.\n",
      " |      \n",
      " |      Args:\n",
      " |          percentage: float between 0 and 100\n",
      " |      \n",
      " |      Returns:\n",
      " |          sequence of two floats, low and high\n",
      " |  \n",
      " |  MakeCdf(self, name=None)\n",
      " |      Makes a Cdf.\n",
      " |  \n",
      " |  Max(self, k)\n",
      " |      Computes the CDF of the maximum of k selections from this dist.\n",
      " |      \n",
      " |      k: int\n",
      " |      \n",
      " |      returns: new Cdf\n",
      " |  \n",
      " |  MaximumLikelihood(self)\n",
      " |      Returns the value with the highest probability.\n",
      " |      \n",
      " |      Returns: float probability\n",
      " |  \n",
      " |  Mean(self)\n",
      " |      Computes the mean of a PMF.\n",
      " |      \n",
      " |      Returns:\n",
      " |          float mean\n",
      " |  \n",
      " |  Normalize(self, fraction=1.0)\n",
      " |      Normalizes this PMF so the sum of all probs is fraction.\n",
      " |      \n",
      " |      Args:\n",
      " |          fraction: what the total should be after normalization\n",
      " |      \n",
      " |      Returns: the total probability before normalizing\n",
      " |  \n",
      " |  Prob(self, x, default=0)\n",
      " |      Gets the probability associated with the value x.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: number value\n",
      " |          default: value to return if the key is not there\n",
      " |      \n",
      " |      Returns:\n",
      " |          float probability\n",
      " |  \n",
      " |  ProbGreater(self, x)\n",
      " |      Probability that a sample from this Pmf exceeds x.\n",
      " |      \n",
      " |      x: number\n",
      " |      \n",
      " |      returns: float probability\n",
      " |  \n",
      " |  ProbLess(self, x)\n",
      " |      Probability that a sample from this Pmf is less than x.\n",
      " |      \n",
      " |      x: number\n",
      " |      \n",
      " |      returns: float probability\n",
      " |  \n",
      " |  Probs(self, xs)\n",
      " |      Gets probabilities for a sequence of values.\n",
      " |  \n",
      " |  Random(self)\n",
      " |      Chooses a random element from this PMF.\n",
      " |      \n",
      " |      Returns:\n",
      " |          float value from the Pmf\n",
      " |  \n",
      " |  Var(self, mu=None)\n",
      " |      Computes the variance of a PMF.\n",
      " |      \n",
      " |      Args:\n",
      " |          mu: the point around which the variance is computed;\n",
      " |              if omitted, computes the mean\n",
      " |      \n",
      " |      Returns:\n",
      " |          float variance\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |      Computes the Pmf of the sum of values drawn from self and other.\n",
      " |      \n",
      " |      other: another Pmf\n",
      " |      \n",
      " |      returns: new Pmf\n",
      " |  \n",
      " |  __eq__(self, obj)\n",
      " |      Less than.\n",
      " |      \n",
      " |      obj: number or _DictWrapper\n",
      " |      \n",
      " |      returns: float probability\n",
      " |  \n",
      " |  __ge__(self, obj)\n",
      " |      Greater than or equal.\n",
      " |      \n",
      " |      obj: number or _DictWrapper\n",
      " |      \n",
      " |      returns: float probability\n",
      " |  \n",
      " |  __gt__(self, obj)\n",
      " |      Greater than.\n",
      " |      \n",
      " |      obj: number or _DictWrapper\n",
      " |      \n",
      " |      returns: float probability\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __le__(self, obj)\n",
      " |      Less than or equal.\n",
      " |      \n",
      " |      obj: number or _DictWrapper\n",
      " |      \n",
      " |      returns: float probability\n",
      " |  \n",
      " |  __lt__(self, obj)\n",
      " |      Less than.\n",
      " |      \n",
      " |      obj: number or _DictWrapper\n",
      " |      \n",
      " |      returns: float probability\n",
      " |  \n",
      " |  __ne__(self, obj)\n",
      " |      Less than.\n",
      " |      \n",
      " |      obj: number or _DictWrapper\n",
      " |      \n",
      " |      returns: float probability\n",
      " |  \n",
      " |  __sub__(self, other)\n",
      " |      Computes the Pmf of the diff of values drawn from self and other.\n",
      " |      \n",
      " |      other: another Pmf\n",
      " |      \n",
      " |      returns: new Pmf\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _DictWrapper:\n",
      " |  \n",
      " |  Copy(self, name=None)\n",
      " |      Returns a copy.\n",
      " |      \n",
      " |      Make a shallow copy of d.  If you want a deep copy of d,\n",
      " |      use copy.deepcopy on the whole object.\n",
      " |      \n",
      " |      Args:\n",
      " |          name: string name for the new Hist\n",
      " |  \n",
      " |  Exp(self, m=None)\n",
      " |      Exponentiates the probabilities.\n",
      " |      \n",
      " |      m: how much to shift the ps before exponentiating\n",
      " |      \n",
      " |      If m is None, normalizes so that the largest prob is 1.\n",
      " |  \n",
      " |  GetDict(self)\n",
      " |      Gets the dictionary.\n",
      " |  \n",
      " |  Incr(self, x, term=1)\n",
      " |      Increments the freq/prob associated with the value x.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: number value\n",
      " |          term: how much to increment by\n",
      " |  \n",
      " |  InitFailure(self, values)\n",
      " |      Raises an error.\n",
      " |  \n",
      " |  InitMapping(self, values)\n",
      " |      Initializes with a map from value to probability.\n",
      " |      \n",
      " |      values: map from value to probability\n",
      " |  \n",
      " |  InitPmf(self, values)\n",
      " |      Initializes with a Pmf.\n",
      " |      \n",
      " |      values: Pmf object\n",
      " |  \n",
      " |  InitSequence(self, values)\n",
      " |      Initializes with a sequence of equally-likely values.\n",
      " |      \n",
      " |      values: sequence of values\n",
      " |  \n",
      " |  Items(self)\n",
      " |      Gets an unsorted sequence of (value, freq/prob) pairs.\n",
      " |  \n",
      " |  Log(self, m=None)\n",
      " |      Log transforms the probabilities.\n",
      " |      \n",
      " |      Removes values with probability 0.\n",
      " |      \n",
      " |      Normalizes so that the largest logprob is 0.\n",
      " |  \n",
      " |  MaxLike(self)\n",
      " |      Returns the largest frequency/probability in the map.\n",
      " |  \n",
      " |  Mult(self, x, factor)\n",
      " |      Scales the freq/prob associated with the value x.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: number value\n",
      " |          factor: how much to multiply by\n",
      " |  \n",
      " |  Print(self)\n",
      " |      Prints the values and freqs/probs in ascending order.\n",
      " |  \n",
      " |  Remove(self, x)\n",
      " |      Removes a value.\n",
      " |      \n",
      " |      Throws an exception if the value is not there.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: value to remove\n",
      " |  \n",
      " |  Render(self)\n",
      " |      Generates a sequence of points suitable for plotting.\n",
      " |      \n",
      " |      Returns:\n",
      " |          tuple of (sorted value sequence, freq/prob sequence)\n",
      " |  \n",
      " |  Scale(self, factor)\n",
      " |      Multiplies the values by a factor.\n",
      " |      \n",
      " |      factor: what to multiply by\n",
      " |      \n",
      " |      Returns: new object\n",
      " |  \n",
      " |  Set(self, x, y=0)\n",
      " |      Sets the freq/prob associated with the value x.\n",
      " |      \n",
      " |      Args:\n",
      " |          x: number value\n",
      " |          y: number freq or prob\n",
      " |  \n",
      " |  SetDict(self, d)\n",
      " |      Sets the dictionary.\n",
      " |  \n",
      " |  Total(self)\n",
      " |      Returns the total of the frequencies/probabilities in the map.\n",
      " |  \n",
      " |  Values(self)\n",
      " |      Gets an unsorted sequence of values.\n",
      " |      \n",
      " |      Note: one source of confusion is that the keys of this\n",
      " |      dictionary are the values of the Hist/Pmf, and the\n",
      " |      values of the dictionary are frequencies/probabilities.\n",
      " |  \n",
      " |  __contains__(self, value)\n",
      " |  \n",
      " |  __init__(self, values=None, name='')\n",
      " |      Initializes the distribution.\n",
      " |      \n",
      " |      hypos: sequence of hypotheses\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  iterkeys(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _DictWrapper:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Pmf)\n",
    "# What is this object? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a [Probability Mass Function](https://en.wikipedia.org/wiki/Probability_mass_function) object, which includes some pre-defined methods and parameters to help us deal with Pmfs (which measures the chance that some disecrete number is equal some value, where all values must sum to 1). \n",
    "\n",
    "Here's a PMF for the fair die problem we will explore below\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Fair_dice_probability_distribution.svg/576px-Fair_dice_probability_distribution.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pmf = Pmf()\n",
    "# intialize the object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pmf()` **creates** an empty Probability Mass Function with no values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.16666666666666666\n",
      "2 0.16666666666666666\n",
      "3 0.16666666666666666\n",
      "4 0.16666666666666666\n",
      "5 0.16666666666666666\n",
      "6 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "for x in [1,2,3,4,5,6]:\n",
    "    # for x in array\n",
    "    \n",
    "    pmf.Set(x, 1/6.0)\n",
    "    # Set the frequency for each x\n",
    "    \n",
    "pmf.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Set` method **sets** the probability associated with each value to $1/6$.\n",
    "\n",
    "Here’s another example that counts the number of times each word appears in a sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bye 1\n",
      "football 1\n",
      "hi 2\n",
      "sky 1\n",
      "the 1\n"
     ]
    }
   ],
   "source": [
    "word_list = ['hi', 'the', 'bye', 'hi', 'football', 'sky']\n",
    "\n",
    "pmf = Pmf()\n",
    "\n",
    "for word in word_list:\n",
    "    pmf.Incr(word, 1)\n",
    "pmf.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Incr` **increases** the “probability” associated with each word (array value) by 1. If a\n",
    "word is not already in the Pmf, it is added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“Probability” is in quotes because in this example, the probabilities are not normalized; that is, they do not add up to 1, so they are *not true probabilities*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in this example the word counts are proportional to the probabilities. So after we count all the words, we can compute probabilities by dividing through by the total number of words.\n",
    "\n",
    "<span>Pmf</span> provides a method, `Normalize`, that does exactly that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bye 0.16666666666666669\n",
      "football 0.16666666666666669\n",
      "hi 0.33333333333333337\n",
      "sky 0.16666666666666669\n",
      "the 0.16666666666666669\n"
     ]
    }
   ],
   "source": [
    "pmf.Normalize()\n",
    "pmf.Print()\n",
    "# wow!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a defined Pmf object, you can ask for the probability associated\n",
    "with any value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666669\n"
     ]
    }
   ],
   "source": [
    "print(pmf.Prob('the'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which returns the frequency of the word “the” as a fraction of the words in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pmf uses a Python dictionary to store the values and their probabilities, so the values in the Pmf can be any [hashable](https://en.wikipedia.org/wiki/Hash_table) type. \n",
    "\n",
    "The probabilities can be any numerical type, but they are usually floating-point numbers (type `float`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cookie Problem\n",
    "---\n",
    "\n",
    "In the context of Bayes’s theorem, it is natural to use a PMF to map from each hypothesis to its probability. \n",
    "\n",
    "In the cookie problem, the hypotheses are $B_1$ and $B_2$. In Python, I represent them with strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowl 1 0.5\n",
      "Bowl 2 0.5\n"
     ]
    }
   ],
   "source": [
    "pmf = Pmf()\n",
    "# Reinitialize the Pmf()\n",
    "\n",
    "pmf.Set('Bowl 1', 0.5)\n",
    "pmf.Set('Bowl 2', 0.5)\n",
    "# Set up the prior distribution; 50/50 odds\n",
    "\n",
    "pmf.Print()\n",
    "# Show us what's in there so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution, which contains the priors for each hypothesis, is called (wait for it) the <span>**prior distribution**</span>.\n",
    "\n",
    "To update the distribution based on new data (the vanilla cookie), we **multiply each prior by the corresponding likelihood**.\n",
    "\n",
    "Here's a visualization of that in action, courtesy of this [amazing post by  Brandon Rohrer](https://brohrer.github.io/how_bayesian_inference_works.html)\n",
    "\n",
    "![](https://brohrer.github.io/images/Bayesian_nonuniform_prior.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the cookie example, the likelihood of drawing a vanilla cookie from Bowl 1 is 3/4. The likelihood for Bowl 2\n",
    "is 1/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `Mult` method to update these probabilities with the Vanilla likelihoods. `Mult` does what you would expect. It gets the probability for the given hypothesis and multiplies by the given likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowl 1 0.375\n",
      "Bowl 2 0.25\n"
     ]
    }
   ],
   "source": [
    "pmf.Mult('Bowl 1', 0.75)\n",
    "pmf.Mult('Bowl 2', 0.5)\n",
    "# Update with the vanilla likelihoods\n",
    "\n",
    "pmf.Print()\n",
    "# Where are we at now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this does not add up to 1. That is because after this update, the distribution is **no longer normalized**, but because these hypotheses are **mutually exclusive and collectively exhaustive**, we can <span>**renormalize**</span>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmf.Normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a distribution that contains the posterior probability for each hypothesis, which is called (wait now) the <span>**posterior distribution**</span>.\n",
    "\n",
    "Check if it's normalized now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmf.Normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can get the posterior probability for Bowl 1, what are the odds of getting that vanilla cookie from Bowl 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6000000000000001"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmf.Prob('Bowl 1')\n",
    "# Odds of getting the Vanilla cookie from Bowl 1? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for fun, Bowl 2? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmf.Prob('Bowl 2')\n",
    "# Odds of getting the Vanilla cookie from Bowl 1? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the answer is 0.6. You can download this example from\n",
    "<http://thinkbayes.com/cookie.py>. For more information see\n",
    "Section [download]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bayesian Framework\n",
    "\n",
    "\n",
    "Before we go on to other problems, I want to rewrite the code from the\n",
    "previous section to make it more general. First I’ll define a class to\n",
    "encapsulate the code related to this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Cookie(Pmf):\n",
    "    \"\"\"A map from string bowl ID to probablity.\"\"\"\n",
    "\n",
    "    def __init__(self, hypos):\n",
    "        \"\"\"Initialize self.\n",
    "\n",
    "        hypos: sequence of string bowl IDs\n",
    "        \"\"\"\n",
    "        Pmf.__init__(self)\n",
    "        # Intializie the Pmf object from before\n",
    "        for hypo in hypos:\n",
    "            #self.Set(hypo, 1)\n",
    "            # For hypo in in array, set to 1\n",
    "            \n",
    "            # For learning, let's see what happens with Pmf.Incr()\n",
    "            # Yields the same result\n",
    "            self.Incr(hypo, 1)\n",
    "            \n",
    "        self.Normalize()\n",
    "        #Renormalize after all the new hypotheses\n",
    "\n",
    "        \n",
    "    mixes = {\n",
    "        'Bowl 1':dict(vanilla=0.75, chocolate=0.25),\n",
    "        'Bowl 2':dict(vanilla=0.5, chocolate=0.5),\n",
    "        }\n",
    "    \n",
    "    # Mix data as provided by the problem. \n",
    "    # Refresher: \n",
    "    # * Bowl 1 contains 30 vanilla cookies and 10 chocolate cookies.\n",
    "    # * Bowl 2 contains 20 of each (10 vanilla, 10 chocolate)\n",
    "    \n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"The likelihood of the data under the hypothesis.\n",
    "\n",
    "        data: string cookie type\n",
    "        hypo: string bowl ID\n",
    "        \"\"\"\n",
    "        mix = self.mixes[hypo]\n",
    "        # Search for the mix of a given hypo ('Bowl 1' or 'Bowl 2')\n",
    "        like = mix[data]\n",
    "        # Likelihood of the prior given the current data in the mixes dict\n",
    "        return like\n",
    "        # Return the likelihood \n",
    "        \n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the PMF with new data.\n",
    "\n",
    "        data: string cookie type\n",
    "        \"\"\"\n",
    "        for hypo in self.Values():\n",
    "        # For every hypo in the current prior distribution    \n",
    "            like = self.Likelihood(data, hypo)\n",
    "            # Get the likelihood value using the Likelihood() method above\n",
    "            self.Mult(hypo, like)\n",
    "            # Multiple the prior by the new Likelihood\n",
    "        self.Normalize()\n",
    "        # Renormalize after all the new updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Cookie object is now a Pmf that maps from hypotheses to their probabilities. \n",
    "\n",
    "The `__init__` method gives each hypothesis with the same prior probability. As in the previous section, there are two hypotheses:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Cookie' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8bd510bf2bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhypos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Bowl 1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Bowl 2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCookie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Run the Cookie object on our hypothesis, using __init__ to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# generate priors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Cookie' is not defined"
     ]
    }
   ],
   "source": [
    "hypos = ['Bowl 1', 'Bowl 2']\n",
    "pmf = Cookie(hypos)\n",
    "# Run the Cookie object on our hypothesis, using __init__ to \n",
    "# generate priors\n",
    "\n",
    "pmf.Print()\n",
    "# Show us the current distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cookie` provides an `Update` method that takes data as a parameter and updates the probabilities.  \n",
    "\n",
    "`Update` loops through each hypothesis in the suite and multiplies its probability by the **likelihood of the data under the hypothesis, which is computed by `Likelihood`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Likelihood` uses the `mixes` parameter, which is a dictionary that maps from the name of a bowl to the mix of cookies in the bowl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bowl 1': {'chocolate': 0.25, 'vanilla': 0.75},\n",
       " 'Bowl 2': {'chocolate': 0.5, 'vanilla': 0.5}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cookie.mixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s what the update looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowl 1 0.6000000000000001\n",
      "Bowl 2 0.4\n"
     ]
    }
   ],
   "source": [
    "pmf.Update('vanilla')\n",
    "# Update using all 'vanilla' entries in the dictionary\n",
    "\n",
    "pmf.Print()\n",
    "# Show us the posterior distribution (post Update via Likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can print the posterior probability of each hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowl 1 0.6000000000000001\n",
      "Bowl 2 0.4\n"
     ]
    }
   ],
   "source": [
    "for hypo, prob in pmf.Items():\n",
    "    print(hypo, prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the same as what we got before. \n",
    "\n",
    "This code is more complicated than what we saw in the previous section, but the advantage is that it generalizes to the case where we draw more than one cookie from the same bowl (with replacement), using the `data` placeholder in the above methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowl 1 0.6549865229110512\n",
      "Bowl 2 0.34501347708894875\n"
     ]
    }
   ],
   "source": [
    "dataset = ['vanilla', 'chocolate', 'vanilla']\n",
    "# 3 draws, here are the results\n",
    "\n",
    "for data in dataset:\n",
    "    pmf.Update(data)\n",
    "    # Update our pmf using the results of our draws\n",
    "pmf.Print()\n",
    "# What's the new distribution? \n",
    "# More refined with new information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other advantage is that it provides a framework for solving many\n",
    "similar problems. \n",
    "\n",
    "In the next section we’ll solve the Monty Hall problem computationally and then see what parts of the framework are the same.\n",
    "\n",
    "The code in this section is available from <http://thinkbayes.com/cookie2.py>. For more information see\n",
    "Section [download]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Monty Hall problem\n",
    "---\n",
    "\n",
    "To solve the Monty Hall problem, we’ll define a new class using the same skeleton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Monty(Pmf):\n",
    "    \"\"\"Map from string location of car to probability\"\"\"\n",
    "\n",
    "    def __init__(self, hypos):\n",
    "        \"\"\"Initialize the prior distribution using the hp\n",
    "\n",
    "        hypos: sequence of hypotheses\n",
    "        \"\"\"\n",
    "        Pmf.__init__(self)\n",
    "        for hypo in hypos:\n",
    "            self.Set(hypo, 1)\n",
    "        self.Normalize()\n",
    "\n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates each hypothesis based on the data.\n",
    "\n",
    "        data: any representation of the data\n",
    "        \"\"\"\n",
    "        for hypo in self.Values():\n",
    "            like = self.Likelihood(data, hypo)\n",
    "            self.Mult(hypo, like)\n",
    "        self.Normalize()\n",
    "\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"Compute the likelihood of the data under the hypothesis.\n",
    "\n",
    "        hypo: string name of the door where the prize is\n",
    "        data: string name of the door Monty opened\n",
    "        \"\"\"\n",
    "        if hypo == data:\n",
    "            return 0\n",
    "        elif hypo == 'A':\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far `Monty` and `Cookie` are nearly the same (ignoring the `Likelihood` method for a second)\n",
    "\n",
    "The code that creates the Pmf is the same, too, except for the names of the hypotheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 0.3333333333333333\n",
      "B 0.3333333333333333\n",
      "C 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "hypos = 'ABC'\n",
    "pmf = Monty(hypos)\n",
    "\n",
    "pmf.Print()\n",
    "# Current prior; all have the same odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `Update` is pretty much the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = 'B'\n",
    "# Opened Door B\n",
    "\n",
    "pmf.Update(data)\n",
    "# Update Prior with the Likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 0.3333333333333333\n",
      "B 0.0\n",
      "C 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "pmf.Print()\n",
    "# Posterior Distribution\n",
    "\n",
    "# Our opened door B in data was not the car, so the odds for Car behind B are now 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of `Update` is exactly the same; we are updating the Prior distribution as defined by the hypothesis using the `Mult` function via `Likelhood`.\n",
    "\n",
    "Speaking of, let's examine the primary change of the new obect, the `Likelihood`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   def Likelihood(self, data, hypo):\n",
    "        \"\"\"Compute the likelihood of the data under the hypothesis.\n",
    "\n",
    "        hypo: string name of the door where the prize is\n",
    "        data: string name of the door Monty opened\n",
    "        \"\"\"\n",
    "        print('Is our hypo {} the same as our data {}?'.format(hypo, data))\n",
    "        if hypo == data:\n",
    "            print('Yes, so the odds of the car beind {} are 0'.format(data))\n",
    "            return 0\n",
    "        elif hypo == 'A':\n",
    "            print('Not A, so the odds update to 50/50, only two doors left')\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, printing the results is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B 0.0\n",
      "C 0.6666666666666666\n",
      "A 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "for hypo, prob in pmf.Items():\n",
    "    print(hypo, prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem centers around the notion of switching; the car is behind one of three doors, and Monty can safely open one door at random.\n",
    "\n",
    "Here that door is in our `data`, door B. Once opened, we need to figure out whether we should stay or switch. Our Bayesian framework suggests that it is in our interest to switch. The logic arrives from the fact that Monty can safely choose between one of two doors that doesn't have the car, which is why the odds become 50/50 if he opens door A.\n",
    "\n",
    "This combined with the data that there is definitely no car behind the door is what powers our switching behavior. Let us examine the other cases (opening door A or C instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Monty(Pmf):\n",
    "    \"\"\"Map from string location of car to probability\"\"\"\n",
    "\n",
    "    def __init__(self, hypos):\n",
    "        \"\"\"Initialize the prior distribution using the hp\n",
    "\n",
    "        hypos: sequence of hypotheses\n",
    "        \"\"\"\n",
    "        Pmf.__init__(self)\n",
    "        for hypo in hypos:\n",
    "            self.Set(hypo, 1)\n",
    "        self.Normalize()\n",
    "\n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates each hypothesis based on the data.\n",
    "\n",
    "        data: any representation of the data\n",
    "        \"\"\"\n",
    "        for hypo in self.Values():\n",
    "            like = self.Likelihood(data, hypo)\n",
    "            self.Mult(hypo, like)\n",
    "        self.Normalize()\n",
    "\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"Compute the likelihood of the data under the hypothesis.\n",
    "\n",
    "        hypo: string name of the door where the prize is\n",
    "        data: string name of the door Monty opened\n",
    "        \"\"\"\n",
    "        if hypo == data:\n",
    "            return 0\n",
    "        elif hypo == 'A':\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, writing `Likelihood` is a little complicated, but the\n",
    "framework of the Bayesian update is simple. The code in this section is\n",
    "available from <http://thinkbayes.com/monty.py>. For more information\n",
    "see Section [download]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulating the framework\n",
    "\n",
    "Now that we see what elements of the framework are the same, we can\n",
    "encapsulate them in an object—a `Suite` is a `Pmf` that provides\n",
    "`__init__`, `Update`, and `Print`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Suite(Pmf):\n",
    "        \"\"\"Represents a suite of hypotheses and their probabilities.\"\"\"\n",
    "\n",
    "        def __init__(self, hypo=tuple()):\n",
    "            \"\"\"Initializes the distribution.\"\"\"\n",
    "\n",
    "        def Update(self, data):\n",
    "            \"\"\"Updates each hypothesis based on the data.\"\"\"\n",
    "\n",
    "        def Print(self):\n",
    "            \"\"\"Prints the hypotheses and their probabilities.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of `Suite` is in `thinkbayes.py`. To use `Suite`, you\n",
    "should write a class that inherits from it and provides `Likelihood`.\n",
    "For example, here is the solution to the Monty Hall problem rewritten to\n",
    "use `Suite`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from thinkbayes import Suite\n",
    "\n",
    "class Monty(Suite):\n",
    "\n",
    "    def Likelihood(self, data, hypo):\n",
    "        if hypo == data:\n",
    "            return 0\n",
    "        elif hypo == 'A':\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here’s the code that uses this class. \n",
    "\n",
    "Once you've updated the `Likelihood` function for the given problem, things get much easier to operationalize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 0.3333333333333333\n",
      "B 0.0\n",
      "C 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "suite = Monty('ABC')\n",
    "suite.Update('B')\n",
    "suite.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download this example from <http://thinkbayes.com/monty2.py>.\n",
    "For more information see Section [download]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The <span>M&M</span> problem\n",
    "\n",
    "We can use the `Suite` framework to solve the <span>M&M</span> problem.\n",
    "Writing the `Likelihood` function is tricky, but everything else is\n",
    "straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The <span>M&M</span> problem\n",
    "\n",
    "<span>M&M</span>’s are small candy-coated chocolates that come in a\n",
    "variety of colors. Mars Inc. which makes <span>M&M</span>’s, changes\n",
    "the mixture of colors from time to time.\n",
    "\n",
    "In 1995, they introduced blue <span>M&M</span>’s. Before then, the color\n",
    "mix in a bag of plain <span>M&M</span>’s was 30% Brown, 20% Yellow, 20%\n",
    "Red, 10% Green, 10% Orange, 10% Tan. Afterward it was 24% Blue , 20%\n",
    "Green, 16% Orange, 14% Yellow, 13% Red, 13% Brown.\n",
    "\n",
    "Suppose a friend of mine has two bags of <span>M&M</span>’s, and he\n",
    "tells me that one is from 1994 and one from 1996. He won’t tell me which\n",
    "is which, but he gives me one <span>M&M</span> from each bag. One is\n",
    "yellow and one is green. What is the probability that the yellow one\n",
    "came from the 1994 bag?\n",
    "\n",
    "This problem is similar to the cookie problem, with the twist that I\n",
    "draw one sample from each bowl/bag.\n",
    "\n",
    "The first step is to enumerate the hypotheses. The bag the yellow\n",
    "<span>M&M</span> came from I’ll call Bag 1; I’ll call the other Bag 2.\n",
    "So the hypotheses are:\n",
    "\n",
    "-   A: Bag 1 is from 1994, which implies that Bag 2 is from 1996.\n",
    "\n",
    "-   B: Bag 1 is from 1996 and Bag 2 from 1994."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the original table method, we can construct a table with a row for each hypothesis and a column for\n",
    "each term in Bayes’s theorem:\n",
    "\n",
    "|  |Prior  $\\mathrm{p}(H)$ | Likelihood $\\mathrm{p}(D\\vert H)$ | $\\mathrm{p}(H) \\mathrm{p}(D\\vert H)$ |  Posterior $\\mathrm{p}(H\\vert D)$|\n",
    "| --- | ---------------- | --------------------------- | ----------- | ------ |\n",
    "| A | 1/2 | (20)(20) | 200 | 20/27|\n",
    "| B | 1/2 | (14)(10) | 70  |   7/27|\n",
    "\n",
    "\n",
    "The first column has the priors. Based on the statement of the problem,\n",
    "it is reasonable to choose\n",
    "${{\\mathrm{p}(A)}} = {{\\mathrm{p}(B)}} = 1/2$.\n",
    "\n",
    "The second column has the likelihoods, which follow from the information\n",
    "in the problem. \n",
    "\n",
    "For example:\n",
    "* **If $A$ is true**, the yellow <span>M&M</span> came from the 1994 bag with probability 20%, and the green came from the 1996 bag with probability 20%. \n",
    "\n",
    "* **If $B$ is true**, the yellow <span>M&M</span> came from the 1996 bag with probability 14%, and the green came from the 1994 bag with probability 10%. \n",
    "\n",
    "Because the selections are independent, we get the conjoint probability by multiplying.\n",
    "\n",
    "The third column is just the product of the previous two. The sum of\n",
    "this column, 270, is the normalizing constant. To get the last column,\n",
    "which contains the posteriors, we divide the third column by the\n",
    "normalizing constant.\n",
    "\n",
    "That’s it. Simple, right?\n",
    "\n",
    "Well, you might be bothered by one detail. I write\n",
    "<span>$\\mathrm{p}(D|H)$</span> in terms of percentages, not\n",
    "probabilities, which means it is off by a factor of 10,000. But that\n",
    "cancels out when we divide through by the normalizing constant, so it\n",
    "doesn’t affect the result.\n",
    "\n",
    "When the set of hypotheses is **mutually exclusive and collectively\n",
    "exhaustive, you can multiply the likelihoods by any factor, if it is\n",
    "convenient**, as long as you apply the same factor to the entire column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from thinkbayes import Suite\n",
    "\n",
    "class M_and_M(Suite):\n",
    "    \"\"\"Map from hypothesis (A or B) to probability.\"\"\"\n",
    "\n",
    "    # Mixes as defined by the problem\n",
    "    \n",
    "    mix94 = dict(brown=30,\n",
    "                 yellow=20,\n",
    "                 red=20,\n",
    "                 green=10,\n",
    "                 orange=10,\n",
    "                 tan=10)\n",
    "    \n",
    "    mix96 = dict(blue=24,\n",
    "                 green=20,\n",
    "                 orange=16,\n",
    "                 yellow=14,\n",
    "                 red=13,\n",
    "                 brown=13)\n",
    "\n",
    "    hypoA = dict(bag1=mix94, bag2=mix96)\n",
    "    hypoB = dict(bag1=mix96, bag2=mix94)\n",
    "    \n",
    "    # Hypothesis using the info, i.e which bag did it come from, 1 or 2? \n",
    "    \n",
    "    hypotheses = dict(A=hypoA, B=hypoB)\n",
    "\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"Computes the likelihood of the data under the hypothesis.\n",
    "\n",
    "        hypo: string hypothesis (A or B)\n",
    "        data: tuple of string bag, string color\n",
    "        \"\"\"\n",
    "        print('The data we observed is {}'.format(data))   \n",
    "        bag, color = data\n",
    "        # Take the bag and color of M&M from the observation\n",
    "        mix = self.hypotheses[hypo][bag]\n",
    "        print('The current hypo we are examing is {}'.format(hypo))\n",
    "        # Pull the mixes for the relevant bag and color\n",
    "        print('The current mix for {} is {}'.format(bag, mix))\n",
    "        like = mix[color]\n",
    "        # Calculate the likelihood of seeing that color\n",
    "        print('Return the number of M&Ms with that color in {} ({}) and renomarlize for likelihood'.format(bag, like))\n",
    "        return like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I need to encode the color mixes from before and after 1995:\n",
    "\n",
    "```python\n",
    "mix94 = dict(brown=30,\n",
    "             yellow=20,\n",
    "             ...\n",
    "\n",
    "mix96 = dict(blue=24,\n",
    "             green=20,\n",
    "             ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I have to encode the hypotheses:\n",
    "\n",
    "```python\n",
    "hypoA = dict(bag1=mix94, bag2=mix96)\n",
    "hypoB = dict(bag1=mix96, bag2=mix94)\n",
    "```\n",
    "\n",
    "`hypoA` represents the hypothesis that Bag 1 is from 1994 and Bag 2 from 1996. `hypoB` is the other way around.\n",
    "\n",
    "Next I map from the name of the hypothesis to the representation:\n",
    "\n",
    "```python\n",
    "hypotheses = dict(A=hypoA, B=hypoB)\n",
    "```\n",
    "\n",
    "And finally I can write `Likelihood`. In this case the hypothesis,\n",
    "`hypo`, is a string, either `A` or `B`. The data is a tuple that\n",
    "specifies a bag and a color.\n",
    "\n",
    "        def Likelihood(self, data, hypo):\n",
    "            bag, color = data\n",
    "            mix = self.hypotheses[hypo][bag]\n",
    "            like = mix[color]\n",
    "            return like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s the code that creates the suite and updates it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The prior probabilities before any observations are:\n",
      "\n",
      "A 0.5\n",
      "B 0.5\n",
      "\n",
      " Where 'A' are the odds the bag is from 1994, and 'B' are the odds that it came from 1996\n",
      "\n",
      "\n",
      " Let us draw the first M&M\n",
      "The data we observed is ('bag1', 'yellow')\n",
      "The current hypo we are examing is A\n",
      "The current mix for bag1 is {'tan': 10, 'red': 20, 'green': 10, 'orange': 10, 'brown': 30, 'yellow': 20}\n",
      "The number of M&Ms with that color in bag1 is 20\n",
      "The data we observed is ('bag1', 'yellow')\n",
      "The current hypo we are examing is B\n",
      "The current mix for bag1 is {'orange': 16, 'red': 13, 'green': 20, 'brown': 13, 'blue': 24, 'yellow': 14}\n",
      "The number of M&Ms with that color in bag1 is 14\n",
      "\n",
      " The posterior probabilities after this observation is now:\n",
      "A 0.5882352941176471\n",
      "B 0.4117647058823529\n",
      "\n",
      " Let us draw another M&M\n",
      "The data we observed is ('bag2', 'green')\n",
      "The current hypo we are examing is A\n",
      "The current mix for bag2 is {'orange': 16, 'red': 13, 'green': 20, 'brown': 13, 'blue': 24, 'yellow': 14}\n",
      "The number of M&Ms with that color in bag2 is 20\n",
      "The data we observed is ('bag2', 'green')\n",
      "The current hypo we are examing is B\n",
      "The current mix for bag2 is {'tan': 10, 'red': 20, 'green': 10, 'orange': 10, 'brown': 30, 'yellow': 20}\n",
      "The number of M&Ms with that color in bag2 is 10\n",
      "\n",
      " The posterior probabilities after pulling both M&Ms is now:\n",
      "A 0.7407407407407407\n",
      "B 0.2592592592592592\n"
     ]
    }
   ],
   "source": [
    "suite = M_and_M('AB')\n",
    "print('\\n The prior probabilities before any observations are:\\n')\n",
    "suite.Print()\n",
    "\n",
    "print('\\n Where \\'A\\' are the odds the bag is from 1994, and \\'B\\' are the odds that it came from 1996\\n')\n",
    "\n",
    "print('\\n Let us draw the first M&M')\n",
    "suite.Update(('bag1', 'yellow'))\n",
    "\n",
    "print('\\n The posterior probabilities after this observation is now:')\n",
    "suite.Print()\n",
    "\n",
    "print('\\n Let us draw another M&M')\n",
    "suite.Update(('bag2', 'green'))\n",
    "\n",
    "print('\\n The posterior probabilities after pulling both M&Ms is now:')\n",
    "suite.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior probability of A is approximately $20/27$, which is what\n",
    "we got before.\n",
    "\n",
    "The code in this section is available from\n",
    "<http://thinkbayes.com/m_and_m.py>. For more information see\n",
    "Section [download]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "This chapter presents the Suite class, which encapsulates the Bayesian\n",
    "update framework.\n",
    "\n",
    "<span>Suite</span> is an <span>**abstract type**</span>, which means\n",
    "that it defines the interface a Suite is supposed to have, but does not\n",
    "provide a complete implementation. The <span>Suite</span> interface\n",
    "includes <span>Update</span> and <span>Likelihood</span>, but the\n",
    "<span>Suite</span> class only provides an implementation of\n",
    "<span>Update</span>, not <span>Likelihood</span>.\n",
    "\n",
    "A <span>**concrete type**</span> is a class that extends an abstract\n",
    "parent class and provides an implementation of the missing methods. For\n",
    "example, <span>Monty</span> extends <span>Suite</span>, so it inherits\n",
    "<span>Update</span> and provides <span>Likelihood</span>.\n",
    "\n",
    "If you are familiar with design patterns, you might recognize this as an\n",
    "example of the template method pattern. You can read about this pattern\n",
    "at <http://en.wikipedia.org/wiki/Template_method_pattern>.\n",
    "\n",
    "Most of the examples in the following chapters follow the same pattern;\n",
    "for each problem we define a new class that extends <span>Suite</span>,\n",
    "inherits <span>Update</span>, and provides <span>Likelihood</span>. In a\n",
    "few cases we override <span>Update</span>, usually to improve\n",
    "performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "In Section [framework] I said that the solution to the cookie problem\n",
    "generalizes to the case where we draw multiple cookies with replacement.\n",
    "\n",
    "But in the more likely scenario where we eat the cookies we draw, the\n",
    "likelihood of each draw depends on the previous draws.\n",
    "\n",
    "Modify the solution in this chapter to handle selection without\n",
    "replacement. Hint: add instance variables to <span>Cookie</span> to\n",
    "represent the hypothetical state of the bowls, and modify\n",
    "<span>Likelihood</span> accordingly. You might want to define a\n",
    "<span>Bowl</span> object."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
